{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc2c23b6-d272-4020-9b40-48d3c548e731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transactions.csv not found. Creating synthetic dataset...\n",
      "Saved: fraud_data_for_powerbi.csv & fraud_by_hour.csv\n",
      "Best Model: Logistic Regression | ROC-AUC: 0.5190\n",
      "Saved model: Fraud_Detection_Output/fraud_detection_model.pkl\n",
      "Saved: fraud_predictions.csv\n",
      "Saved: feature_importance.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53ecd813acd42e3917ece116bec3ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Dropdown(description='Age Group:', options=('All', '18-24', '25-3â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------- FULL FRAUD DETECTION PROJECT + DASHBOARD --------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "from ipywidgets import widgets, VBox, HBox, Output\n",
    "from IPython.display import display\n",
    "\n",
    "# -------------------- 1. CREATE OUTPUT FOLDER --------------------\n",
    "output_folder = \"Fraud_Detection_Output\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# -------------------- 2. LOAD OR CREATE DATA --------------------\n",
    "try:\n",
    "    df = pd.read_csv(\"transactions.csv\")\n",
    "    print(\"Loaded dataset successfully!\")\n",
    "except:\n",
    "    print(\"transactions.csv not found. Creating synthetic dataset...\")\n",
    "    np.random.seed(42)\n",
    "    df = pd.DataFrame({\n",
    "        \"transaction_id\": range(1,5001),\n",
    "        \"amount\": np.random.uniform(1, 5000, 5000),\n",
    "        \"age\": np.random.randint(18, 75, 5000),\n",
    "        \"is_international\": np.random.randint(0, 2, 5000),\n",
    "        \"merchant_cat\": np.random.randint(1, 20, 5000),\n",
    "        \"hour\": np.random.randint(0, 24, 5000),\n",
    "        \"device_change\": np.random.randint(0, 2, 5000),\n",
    "        \"fraud\": np.random.randint(0, 2, 5000)\n",
    "    })\n",
    "\n",
    "# -------------------- 3. CREATE AGE GROUP --------------------\n",
    "def get_age_group(age):\n",
    "    if age < 25:\n",
    "        return \"18-24\"\n",
    "    elif age < 35:\n",
    "        return \"25-34\"\n",
    "    elif age < 45:\n",
    "        return \"35-44\"\n",
    "    elif age < 55:\n",
    "        return \"45-54\"\n",
    "    elif age < 65:\n",
    "        return \"55-64\"\n",
    "    else:\n",
    "        return \"65+\"\n",
    "\n",
    "df[\"age_group\"] = df[\"age\"].apply(get_age_group)\n",
    "\n",
    "# -------------------- 4. FRAUD % BY HOUR --------------------\n",
    "hourly_stats = df.groupby(\"hour\")[\"fraud\"].mean().reset_index().rename(columns={\"fraud\":\"fraud_percent_by_hour\"})\n",
    "df = df.merge(hourly_stats, on=\"hour\", how=\"left\")\n",
    "\n",
    "# -------------------- 5. SAVE BASE CSVs --------------------\n",
    "df.to_csv(f\"{output_folder}/fraud_data_for_powerbi.csv\", index=False)\n",
    "hourly_stats.to_csv(f\"{output_folder}/fraud_by_hour.csv\", index=False)\n",
    "print(\"Saved: fraud_data_for_powerbi.csv & fraud_by_hour.csv\")\n",
    "\n",
    "# -------------------- 6. PREPROCESS & TRAIN MODELS --------------------\n",
    "X = df.drop([\"fraud\",\"transaction_id\",\"age_group\",\"fraud_percent_by_hour\"], axis=1)\n",
    "y = df[\"fraud\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=150, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=120, learning_rate=0.1, max_depth=5, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "roc_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    trained_models[name] = model\n",
    "    prob = model.predict_proba(X_test)[:,1]\n",
    "    roc_scores[name] = roc_auc_score(y_test, prob)\n",
    "\n",
    "best_model_name = max(roc_scores, key=roc_scores.get)\n",
    "best_model = trained_models[best_model_name]\n",
    "print(f\"Best Model: {best_model_name} | ROC-AUC: {roc_scores[best_model_name]:.4f}\")\n",
    "\n",
    "joblib.dump(best_model, f\"{output_folder}/fraud_detection_model.pkl\")\n",
    "print(f\"Saved model: {output_folder}/fraud_detection_model.pkl\")\n",
    "\n",
    "# -------------------- 7. SAVE PREDICTIONS CSV --------------------\n",
    "pred_test = best_model.predict(X_test)\n",
    "prob_test = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "predictions_df = df.loc[y_test.index, [\"transaction_id\",\"amount\",\"age\",\"age_group\",\n",
    "                                       \"is_international\",\"merchant_cat\",\"hour\",\n",
    "                                       \"device_change\",\"fraud\",\"fraud_percent_by_hour\"]].copy()\n",
    "predictions_df[\"predicted_fraud\"] = pred_test\n",
    "predictions_df[\"fraud_probability\"] = prob_test\n",
    "predictions_df.to_csv(f\"{output_folder}/fraud_predictions.csv\", index=False)\n",
    "print(\"Saved: fraud_predictions.csv\")\n",
    "\n",
    "# -------------------- 8. SAVE FEATURE IMPORTANCE CSV (ALL MODELS) --------------------\n",
    "if isinstance(best_model, RandomForestClassifier):\n",
    "    feat_importance = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"importance\": best_model.feature_importances_\n",
    "    }).sort_values(by=\"importance\", ascending=False)\n",
    "elif isinstance(best_model, XGBClassifier):\n",
    "    importance_dict = best_model.get_booster().get_score(importance_type='weight')\n",
    "    feat_importance = pd.DataFrame({\n",
    "        \"feature\": list(importance_dict.keys()),\n",
    "        \"importance\": list(importance_dict.values())\n",
    "    }).sort_values(by=\"importance\", ascending=False)\n",
    "else:  # Logistic Regression\n",
    "    feat_importance = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"importance\": abs(best_model.coef_[0])\n",
    "    }).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "feat_importance.to_csv(f\"{output_folder}/feature_importance.csv\", index=False)\n",
    "print(\"Saved: feature_importance.csv\")\n",
    "\n",
    "# -------------------- 9. INTERACTIVE DASHBOARD --------------------\n",
    "out = Output()\n",
    "\n",
    "age_dropdown = widgets.Dropdown(\n",
    "    options=[\"All\"] + sorted(df[\"age_group\"].unique()),\n",
    "    value=\"All\",\n",
    "    description=\"Age Group:\"\n",
    ")\n",
    "\n",
    "fraud_dropdown = widgets.Dropdown(\n",
    "    options=[\"All\",\"Fraud\",\"Non-Fraud\"],\n",
    "    value=\"All\",\n",
    "    description=\"Class:\"\n",
    ")\n",
    "\n",
    "def filtered_df(age_group):\n",
    "    if age_group == \"All\":\n",
    "        return df.copy()\n",
    "    else:\n",
    "        return df[df[\"age_group\"] == age_group].copy()\n",
    "\n",
    "def save_and_show_plot(fig, filename):\n",
    "    fig.savefig(f\"{output_folder}/{filename}.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_fraud_count(age_group):\n",
    "    with out:\n",
    "        out.clear_output(wait=True)\n",
    "        data = filtered_df(age_group)\n",
    "        fig, ax = plt.subplots(figsize=(6,4))\n",
    "        sns.countplot(data=data, x=\"fraud\", ax=ax)\n",
    "        ax.set_title(f\"Fraud vs Non-Fraud Count - Age Group: {age_group}\")\n",
    "        save_and_show_plot(fig, f\"fraud_count_{age_group}\")\n",
    "\n",
    "def plot_correlation(age_group):\n",
    "    with out:\n",
    "        out.clear_output(wait=True)\n",
    "        data = filtered_df(age_group)\n",
    "        numeric_cols = data.select_dtypes(include=np.number).columns\n",
    "        fig, ax = plt.subplots(figsize=(10,6))\n",
    "        sns.heatmap(data[numeric_cols].corr(), annot=True, cmap=\"Blues\", ax=ax)\n",
    "        ax.set_title(f\"Correlation Heatmap - Age Group: {age_group}\")\n",
    "        save_and_show_plot(fig, f\"correlation_heatmap_{age_group}\")\n",
    "\n",
    "def plot_amount_distribution(age_group, fraud_class):\n",
    "    with out:\n",
    "        out.clear_output(wait=True)\n",
    "        data = filtered_df(age_group)\n",
    "        fig, ax = plt.subplots(figsize=(8,5))\n",
    "        if fraud_class==\"All\":\n",
    "            sns.kdeplot(data=data, x=\"amount\", hue=\"fraud\", fill=True, ax=ax)\n",
    "        else:\n",
    "            cls = 1 if fraud_class==\"Fraud\" else 0\n",
    "            sns.kdeplot(data=data[data[\"fraud\"]==cls], x=\"amount\", fill=True, ax=ax)\n",
    "        ax.set_title(f\"Transaction Amount Distribution - {fraud_class} - Age Group: {age_group}\")\n",
    "        save_and_show_plot(fig, f\"amount_distribution_{fraud_class}_{age_group}\")\n",
    "\n",
    "def plot_feature_importance(age_group):\n",
    "    with out:\n",
    "        out.clear_output(wait=True)\n",
    "        fig, ax = plt.subplots(figsize=(10,5))\n",
    "        sns.barplot(x=\"feature\", y=\"importance\", data=feat_importance, palette=\"Greens\", ax=ax)\n",
    "        ax.set_title(f\"Feature Importance - {best_model_name} - Age Group: {age_group}\")\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "        save_and_show_plot(fig, f\"feature_importance_{age_group}\")\n",
    "\n",
    "def plot_fraud_by_hour(age_group):\n",
    "    with out:\n",
    "        out.clear_output(wait=True)\n",
    "        data = filtered_df(age_group)\n",
    "        hourly = data.groupby(\"hour\")[\"fraud\"].mean().reset_index()\n",
    "        fig, ax = plt.subplots(figsize=(10,5))\n",
    "        sns.barplot(data=hourly, x=\"hour\", y=\"fraud\", palette=\"Reds\", ax=ax)\n",
    "        ax.set_title(f\"Fraud % by Transaction Hour - Age Group: {age_group}\")\n",
    "        ax.set_ylabel(\"Fraud %\")\n",
    "        save_and_show_plot(fig, f\"fraud_by_hour_{age_group}\")\n",
    "\n",
    "def plot_confusion_matrix(age_group):\n",
    "    with out:\n",
    "        out.clear_output(wait=True)\n",
    "        cm = confusion_matrix(y_test, pred_test)\n",
    "        fig, ax = plt.subplots(figsize=(5,4))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", ax=ax)\n",
    "        ax.set_title(f\"Confusion Matrix - {best_model_name}\")\n",
    "        ax.set_xlabel(\"Predicted\")\n",
    "        ax.set_ylabel(\"Actual\")\n",
    "        save_and_show_plot(fig, f\"confusion_matrix_{age_group}\")\n",
    "\n",
    "# Buttons\n",
    "button_fraud_count = widgets.Button(description=\"Fraud Count\")\n",
    "button_correlation = widgets.Button(description=\"Correlation Heatmap\")\n",
    "button_amount_dist = widgets.Button(description=\"Amount Distribution\")\n",
    "button_feature_importance = widgets.Button(description=\"Feature Importance\")\n",
    "button_fraud_hour = widgets.Button(description=\"Fraud % by Hour\")\n",
    "button_conf_matrix = widgets.Button(description=\"Confusion Matrix\")\n",
    "\n",
    "button_fraud_count.on_click(lambda x: plot_fraud_count(age_dropdown.value))\n",
    "button_correlation.on_click(lambda x: plot_correlation(age_dropdown.value))\n",
    "button_amount_dist.on_click(lambda x: plot_amount_distribution(age_dropdown.value, fraud_dropdown.value))\n",
    "button_feature_importance.on_click(lambda x: plot_feature_importance(age_dropdown.value))\n",
    "button_fraud_hour.on_click(lambda x: plot_fraud_by_hour(age_dropdown.value))\n",
    "button_conf_matrix.on_click(lambda x: plot_confusion_matrix(age_dropdown.value))\n",
    "\n",
    "controls = VBox([\n",
    "    HBox([age_dropdown, fraud_dropdown]),\n",
    "    button_fraud_count,\n",
    "    button_correlation,\n",
    "    button_amount_dist,\n",
    "    button_feature_importance,\n",
    "    button_fraud_hour,\n",
    "    button_conf_matrix\n",
    "])\n",
    "\n",
    "dashboard = VBox([controls, out])\n",
    "display(dashboard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b81ba0-37f3-4b73-8b22-fb6132b69a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
